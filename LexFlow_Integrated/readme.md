README.md

Markdown
# âš–ï¸ LexFlow Integrated Suite

**LexFlow** is a unified legal technology platform designed to streamline legal workflows. It combines Client Management, AI-Powered Legal Drafting, and Intelligent Legal Research into a single, cohesive application.

---

## ğŸ—ï¸ Architecture

This project uses a **Client-Server Architecture**:

* **Backend (API):** Built with **FastAPI**. It handles all business logic, database operations (SQLite), file processing, and AI interactions (OpenAI/DuckDuckGo).
* **Frontend (UI):** Built with **Streamlit**. It acts as a client that consumes the Backend API to display data and interact with the user.

---

## ğŸš€ Key Features

### 1. ğŸ—‚ï¸ Client Workspace
* **Client Database:** Register, update, and manage client profiles.
* **Mandatory Compliance:** Fields for **PAN** and **GSTIN** are now mandatory for compliance tracking.
* **Document Repository:** Upload and organize legal documents (PDF/DOCX) per client.
* **AI Timeline:** Automatically extracts key dates and events from uploaded case files.
* **Communication Log:** Track emails and messages; draft replies using AI.

### 2. ğŸ“ Drafting Studio
* **AI Drafting:** Generate legal documents (Notices, Agreements, Replies) based on custom facts.
* **RAG Context:** Select existing client documents to provide context for the draft without re-uploading.
* **Refinement Tools:** "Make Stronger", "Make Polite", and "Suggest Case Laws" tools.
* **Export:** Download drafts as `.docx` or `.pdf`.

### 3. ğŸ¤– Legal Intelligence & Chatbot
* **Authentic Search:** Searches **ONLY** trusted domains (Indian Kanoon, Taxmann, SC/HC websites) using the `site:` operator.
* **Document Chat:** Ask questions to your uploaded documents (RAG).
* **Judgment Comparison:** Upload two judgments to analyze differences in reasoning and outcome.
* **Appeal Grounds:** Generate structured grounds of appeal from an order.

---

## ğŸ“‚ Project Structure

```text
LexFlow_Integrated/
â”œâ”€â”€ .env                     # API Keys and Config
â”œâ”€â”€ frontend_api.py          # Bridge: Frontend calls to Backend API
â”œâ”€â”€ Home.py                  # Streamlit Entry Point
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI Server (Endpoints)
â”‚   â”œâ”€â”€ database.py          # SQLite Database Handler
â”‚   â”œâ”€â”€ api_schemas.py       # Pydantic Models (Data Validation)
â”‚   â”œâ”€â”€ client_ai.py         # AI Agent for Client Summaries
â”‚   â”œâ”€â”€ chatbot/
â”‚   â”‚   â””â”€â”€ logic.py         # Legal Search & Chat Logic
â”‚   â”œâ”€â”€ drafting/
â”‚   â”‚   â”œâ”€â”€ draft_engine.py  # AI Drafting Logic
â”‚   â”‚   â”œâ”€â”€ export_engine.py # PDF/Word Conversion
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ chunk_and_index.py # FAISS/Vector Store Logic
â”‚       â””â”€â”€ ...
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ lexflow.db           # SQLite Database File
â”‚   â”œâ”€â”€ uploads/             # Stored Documents
â”‚   â””â”€â”€ index_data/          # FAISS Indexes
â””â”€â”€ pages/
    â”œâ”€â”€ 1_ğŸ—‚ï¸_Client_Workspace.py
    â”œâ”€â”€ 2_ğŸ“_Drafting_Studio.py
    â””â”€â”€ 3_ğŸ¤–_Client_Chatbot.py
ğŸ› ï¸ Setup & Installation
1. Prerequisites

Python 3.9+

An OpenAI API Key

2. Install Dependencies

Bash
pip install fastapi uvicorn streamlit python-dotenv openai duckduckgo-search langchain chromadb faiss-cpu python-docx pdfplumber pypdf2 requests
3. Environment Configuration

Create a .env file in the root directory and add your keys:

Ini, TOML
OPENAI_API_KEY=sk-your-key-here
MAIL_USERNAME=your-email@gmail.com  # Optional (for emailing drafts)
MAIL_PASSWORD=your-app-password     # Optional
â–¶ï¸ How to Run
You need to run the Backend and Frontend in two separate terminals.

Terminal 1: Start the Backend (API)

This starts the FastAPI server on http://localhost:8000.

Bash
uvicorn backend.main:app --reload --port 8000
Wait until you see: Application startup complete.

Terminal 2: Start the Frontend (UI)

This starts the Streamlit interface.

Bash
streamlit run Home.py

ğŸ“š API Documentation
Once the backend is running, you can view the automatic interactive API documentation at:

Swagger UI: http://localhost:8000/docs

ReDoc: http://localhost:8000/redoc

This is useful for the frontend team to understand how to integrate with the backend endpoints.

âš ï¸ Notes for Deployment
Database: This project currently uses SQLite (data/lexflow.db). For production deployment on platforms like Vercel (which are serverless), you MUST migrate to a cloud database like PostgreSQL (e.g., Supabase, Neon) to avoid data loss.

File Storage: Similarly, local file uploads (data/uploads) will be lost on serverless platforms. Use AWS S3 or Google Cloud Storage for production.